{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCNN RSNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Colab_Notebooks/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download deltaechov/rnsamamographt512px8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip rnsamamographt512px8bit.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io, transform, color\n",
    "from numpy.ma.core import MaskedConstant\n",
    "import torch\n",
    "import torch.utils.data.dataloader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch.utils.data import RandomSampler, DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from morph2d import Morph2d\n",
    "from pseudoinversemod import pseudoInverse\n",
    "from tabulate import tabulate\n",
    "import datetime\n",
    "import random\n",
    "import scipy\n",
    "from torchmetrics.functional import roc\n",
    "from CIDeLong import delong_roc_variance\n",
    "from scipy import stats\n",
    "from MCNN import MCNN\n",
    "from breastcancerdataset import BreastCancerDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnsa = pd.read_csv('/content/train.csv')\n",
    "\n",
    "# Drop duplicates\n",
    "cases = rnsa.patient_id.unique()\n",
    "print(\"Initial number of patients: \", len(cases))\n",
    "print(\"Initial number of images: \", len(rnsa))\n",
    "\n",
    "cleaned_rnsa = rnsa.drop_duplicates(subset = [\"patient_id\", \"laterality\", \"view\"])\n",
    "cleaned_rnsa = cleaned_rnsa.drop(index=cleaned_rnsa[cleaned_rnsa[\"view\"]=='AT'].index)\n",
    "cleaned_rnsa = cleaned_rnsa.drop(index=cleaned_rnsa[cleaned_rnsa[\"view\"]=='LM'].index)\n",
    "cleaned_rnsa = cleaned_rnsa.drop(index=cleaned_rnsa[cleaned_rnsa[\"view\"]=='ML'].index)\n",
    "cleaned_rnsa = cleaned_rnsa.drop(index=cleaned_rnsa[cleaned_rnsa[\"view\"]=='LMO'].index)\n",
    "\n",
    "cleaned_cases = cleaned_rnsa.patient_id.unique()\n",
    "\n",
    "ordered_index = []\n",
    "for id in cleaned_cases:\n",
    "    aux = cleaned_rnsa[cleaned_rnsa[\"patient_id\"]==id]\n",
    "    ordered_index.append(aux[aux[\"laterality\"]== 'L'][aux[\"view\"]=='CC'].index[0])\n",
    "    ordered_index.append(aux[aux[\"laterality\"]== 'L'][aux[\"view\"]=='MLO'].index[0])\n",
    "    ordered_index.append(aux[aux[\"laterality\"]== 'R'][aux[\"view\"]=='CC'].index[0])\n",
    "    ordered_index.append(aux[aux[\"laterality\"]== 'R'][aux[\"view\"]=='MLO'].index[0])\n",
    "\n",
    "cleaned_rnsa = cleaned_rnsa.reindex(ordered_index)\n",
    "\n",
    "print(\"Final number of patients: \", len(cleaned_cases))\n",
    "print(\"Final number of images: \", len(cleaned_rnsa))\n",
    "\n",
    "cleaned_rnsa.to_csv('/content/cleaned_rnsa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create auxiliar csv\n",
    "\n",
    "# Remove deuplicates\n",
    "for id in cleaned_cases:\n",
    "    aux = cleaned_rnsa[cleaned_rnsa[\"patient_id\"]==id]\n",
    "    if any(aux[\"cancer\"]==1):\n",
    "        aux[\"cancer\"] = 1\n",
    "        cleaned_rnsa[cleaned_rnsa[\"patient_id\"]==id] = aux\n",
    "\n",
    "auxiliar_rnsa = cleaned_rnsa.drop_duplicates(subset = [\"patient_id\"])\n",
    "\n",
    "# Choose dataset size\n",
    "positives = auxiliar_rnsa[auxiliar_rnsa[\"cancer\"]==1].iloc[0:500,:]\n",
    "negatives = auxiliar_rnsa[auxiliar_rnsa[\"cancer\"]==0].iloc[0:500,:]\n",
    "frames = [positives, negatives]\n",
    "auxiliar_rnsa = pd.concat(frames)\n",
    "\n",
    "auxiliar_rnsa.to_csv('/content/auxiliar_rnsa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_original_folder = '/content/train_images_512px8bit/train_images'\n",
    "path_cases_df = '/content/auxiliar_rnsa.csv'\n",
    "path_complete_df = '/content/cleaned_rnsa.csv'\n",
    "path_train_folder = '/content/Train_RNSA'\n",
    "path_test_folder = '/content/Test_RNSA'\n",
    "seed = 28\n",
    "\n",
    "rnsa_df = pd.read_csv(path_cases_df)\n",
    "rnsa_complete = pd.read_csv(path_complete_df)\n",
    "rnsa_df = rnsa_df.sample(frac=1, random_state=seed)\n",
    "\n",
    "train_indices, test_indices = train_test_split(list(range(len(rnsa_df))),\n",
    "                                               test_size=0.3,\n",
    "                                               stratify=rnsa_df[\"cancer\"],\n",
    "                                               random_state = seed)\n",
    "\n",
    "train_rnsa = rnsa_df.loc[train_indices]\n",
    "test_rnsa = rnsa_df.loc[test_indices]\n",
    "train_rnsa.to_csv('/content/train_rnsa.csv')\n",
    "test_rnsa.to_csv('/content/test_rnsa.csv')\n",
    "test_rnsa[\"patient_id\"].to_csv('/content/test_patients_list.csv')\n",
    "\n",
    "# Obtain indices/names\n",
    "os.mkdir(path_train_folder)\n",
    "os.mkdir(path_test_folder)\n",
    "\n",
    "for patient in train_rnsa[\"patient_id\"]:\n",
    "    folder_name = os.path.join(path_train_folder, str(patient))\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "    per_folder = rnsa_complete[rnsa_complete[\"patient_id\"]==patient]\n",
    "    folder_original = os.path.join(path_original_folder, str(patient))\n",
    "\n",
    "    for name in per_folder[\"image_id\"]:\n",
    "        full_name = str(name)+\".png\"\n",
    "        image_name = os.path.join(folder_original, full_name)\n",
    "        image = io.imread(image_name)\n",
    "        fname = os.path.join(folder_name, full_name)\n",
    "        io.imsave(fname, image)\n",
    "\n",
    "for patient in test_rnsa[\"patient_id\"]:\n",
    "    folder_name = os.path.join(path_test_folder, str(patient))\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "    per_folder = rnsa_complete[rnsa_complete[\"patient_id\"]==patient]\n",
    "    folder_original = os.path.join(path_original_folder, str(patient))\n",
    "\n",
    "    for name in per_folder[\"image_id\"]:\n",
    "        full_name = str(name)+\".png\"\n",
    "        image_name = os.path.join(folder_original, full_name)\n",
    "        image = io.imread(image_name)\n",
    "        fname = os.path.join(folder_name, full_name)\n",
    "        io.imsave(fname, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Settings\n",
    "batch_size = 560\n",
    "test_batch_size = 300\n",
    "num_train_samples = 560\n",
    "num_test_samples = 300\n",
    "stop_train = num_train_samples/batch_size\n",
    "stop_test = num_test_samples/test_batch_size\n",
    "seed = 28\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "# Training settings\n",
    "\n",
    "breast_train_dataset = BreastCancerDataset(csv_file='/content/train_rnsa.csv',\n",
    "                              csv_file_full='/content/cleaned_rnsa.csv',\n",
    "                              root_dir='/content/Train_RNSA/',\n",
    "                              transform=transforms.Compose([\n",
    "                                               Rescale(256),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(breast_train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           worker_init_fn=seed_worker,\n",
    "                                           generator=g)\n",
    "\n",
    "# Testing settings\n",
    "\n",
    "breast_test_dataset = BreastCancerDataset(csv_file='/content/test_rnsa.csv',\n",
    "                              csv_file_full='/content/cleaned_rnsa.csv',\n",
    "                              root_dir='/content/Test_RNSA/',\n",
    "                              transform=transforms.Compose([\n",
    "                                               Rescale(256),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(breast_test_dataset,\n",
    "                                          batch_size=test_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          worker_init_fn=seed_worker,\n",
    "                                          generator=g)\n",
    "\n",
    "# Three definitions, each per channel, for weights' independance\n",
    "model_1 = MCNN()\n",
    "model_2 = MCNN()\n",
    "model_3 = MCNN()\n",
    "model_4 = MCNN()\n",
    "\n",
    "optimizer_1 = pseudoInverse(params=model_1.parameters(), C=1)\n",
    "optimizer_2 = pseudoInverse(params=model_2.parameters(), C=1e-3)\n",
    "optimizer_3 = pseudoInverse(params=model_3.parameters(), C=2)\n",
    "optimizer_4 = pseudoInverse(params=model_4.parameters(), C=1)\n",
    "\n",
    "def plot_auc(fpr, tpr, auc_result):\n",
    "\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.plot(fpr, tpr, linewidth=1, color='blue')\n",
    "    plt.plot(np.linspace(0, max(fpr), len(fpr)),\n",
    "             np.linspace(0, max(tpr), len(tpr)),\n",
    "             \"--\", linewidth=0.8, color=\"black\")\n",
    "    plt.title(label=\"ROC-AUC. MCNN\",\n",
    "             fontsize=15,\n",
    "             fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend([\"AUC: \" + str(round(auc_result.item(), 3))], loc='right')\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(right=max(tpr))\n",
    "    plt.ylim(top=max(fpr))\n",
    "\n",
    "def final_classifier(out_train_1, out_train_2, out_train_3, out_train_4, out_test_1,\n",
    "                     out_test_2, out_test_3, out_test_4, target_train, target_test):\n",
    "    \"\"\"This function performs a final classification considering the independent\n",
    "    DPFs obtained from the MCNN method.\n",
    "    \n",
    "    inputs:\n",
    "      out_trains = DPFs obtained per channel from the training set, it contains\n",
    "                   the probabilities of both classes [# classes, # subjects].\n",
    "      out_tests = DPFs obtained per channel from the testing set, it contains\n",
    "                  the probabilities of both classes [# classes, # subjects].\n",
    "      target_train = Labels corresponding to the subjects in the training set.\n",
    "      target_test = Labels corresponding to the subjects in the testing set.\"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Initial definitions\n",
    "    model1 = GaussianNB()\n",
    "    model2 = svm.SVC(random_state=seed, probability=True)\n",
    "    model3 = AdaBoostClassifier(random_state=seed)\n",
    "    model4 = RandomForestClassifier(random_state=seed)\n",
    "    model = [model1, model2, model3, model4]\n",
    "\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    acc_balanced = []\n",
    "    ci_bacc = []\n",
    "    ci_acc = []\n",
    "    conf_mat = []\n",
    "    auc = []\n",
    "    auc_delong = []\n",
    "    auc_cov = []\n",
    "    ci_auc = []\n",
    "    err = []\n",
    "    fpr_all = []\n",
    "    tpr_all = []\n",
    "    p_fpr_all = []\n",
    "    p_tpr_all = []\n",
    "\n",
    "    count = 1\n",
    "    alpha = 0.95\n",
    "    confidence = 0.95\n",
    "    z_value = stats.norm.ppf((1 + confidence) / 2.0)\n",
    "\n",
    "    acc_train.append(\"Train set accuracy\")\n",
    "    acc_test.append(\"Test set accuracy\")\n",
    "    acc_balanced.append(\"Balanced accuracy\")\n",
    "    ci_bacc.append(\"CI Balanced acc\")\n",
    "    ci_acc.append(\"CI Acc\")\n",
    "    auc.append(\"ROC AUC score\")\n",
    "    auc_delong.append(\"ROC AUC DeLong\")\n",
    "    ci_auc.append(\"CI AUC\")\n",
    "    auc_cov.append(\"AUC COV\")\n",
    "    err.append(\"Error\")\n",
    "    headers = [\"Metrics\", \"Gaussian Naive Bayes\", \"SVM\",\n",
    "                        \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "    # Input data preparation\n",
    "    out_train_1 = out_train_1.detach().numpy()\n",
    "    out_train_2 = out_train_2.detach().numpy()\n",
    "    out_train_3 = out_train_3.detach().numpy()\n",
    "    out_train_4 = out_train_4.detach().numpy()\n",
    "    target_train = target_train.detach().numpy()\n",
    "    target_test = target_test.detach().numpy()\n",
    "\n",
    "    target_train = target_train[:,0]\n",
    "    target_test = target_test[:,0]\n",
    "\n",
    "    joint_train = np.vstack((out_train_1[:,0],\n",
    "                             out_train_2[:,0],\n",
    "                             out_train_3[:,0],\n",
    "                             out_train_4[:,0]))\n",
    "    joint_train = np.transpose(joint_train)\n",
    "    joint_train = pd.DataFrame(joint_train)\n",
    "\n",
    "    out_test_1 = out_test_1.detach().numpy()\n",
    "    out_test_2 = out_test_2.detach().numpy()\n",
    "    out_test_3 = out_test_3.detach().numpy()\n",
    "    out_test_4 = out_test_4.detach().numpy()\n",
    "\n",
    "    joint_test = np.vstack((out_test_1[:,0],\n",
    "                            out_test_2[:,0],\n",
    "                            out_test_3[:,0],\n",
    "                            out_test_4[:,0]))\n",
    "    joint_test = np.transpose(joint_test)\n",
    "    joint_test = pd.DataFrame(joint_test)\n",
    "\n",
    "    # Training\n",
    "    for mod in model:\n",
    "        trained_model = mod.fit(joint_train,target_train)\n",
    "        trained_model.fit(joint_train, target_train) #Temporal CORER CON COMENTARIO\n",
    "        acc_train_ind = metrics.accuracy_score(target_train,\n",
    "                                               trained_model.predict(joint_train))\n",
    "        acc_train.append(acc_train_ind)\n",
    "\n",
    "    # Testing\n",
    "    for mod in model: \n",
    "        predicted = mod.predict(joint_test)\n",
    "        probs = mod.predict_proba(joint_test)\n",
    "        acc_test_ind = metrics.accuracy_score(target_test, predicted)\n",
    "        auc_ind = roc_auc_score(target_test, probs[:,1])\n",
    "        acc_balanced_ind = balanced_accuracy_score(target_test, predicted)\n",
    "        fpr, tpr, thresholds = roc_curve(target_test, probs[:,1], pos_label=1)\n",
    "        p_fpr, p_tpr, _ = roc_curve(target_test, predicted, pos_label=1)\n",
    "        err_ind = 1 - acc_test_ind\n",
    "\n",
    "        auc_ind_delong, auc_ind_cov = delong_roc_variance(target_test,\n",
    "                                                          probs[:,1])\n",
    "        \n",
    "        # AUC CIs\n",
    "        auc_std = np.sqrt(auc_ind_cov)\n",
    "        lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "        ci_auc_ind = stats.norm.ppf(\n",
    "            lower_upper_q,\n",
    "            loc=auc_ind_delong,\n",
    "            scale=auc_std)\n",
    "\n",
    "        ci_auc_ind[ci_auc_ind > 1] = 1\n",
    "        ci_auc_ind[0] = round(ci_auc_ind[0], 3)\n",
    "        ci_auc_ind[1] = round(ci_auc_ind[1], 3)\n",
    "\n",
    "        # Acc CIs\n",
    "        ci_length = z_value * np.sqrt((acc_test_ind * (1 - acc_test_ind)) / joint_test.shape[0])\n",
    "        ci_lower = acc_test_ind - ci_length\n",
    "        ci_upper = acc_test_ind + ci_length\n",
    "        ci_acc_ind = (round(ci_lower, 3), round(ci_upper, 3))\n",
    "\n",
    "        # Balanced acc CIs\n",
    "        ci_length = z_value * np.sqrt((acc_balanced_ind * (1 - acc_balanced_ind)) / joint_test.shape[0])\n",
    "        ci_lower = acc_balanced_ind - ci_length\n",
    "        ci_upper = acc_balanced_ind + ci_length\n",
    "        ci_bacc_ind = (round(ci_lower, 3), round(ci_upper, 3))\n",
    "\n",
    "        acc_test.append(round(acc_test_ind, 3))\n",
    "        ci_acc.append(ci_acc_ind)\n",
    "        acc_balanced.append(round(acc_balanced_ind, 3))\n",
    "        ci_bacc.append(ci_bacc_ind)\n",
    "        auc_delong.append(round(auc_ind_delong, 3))\n",
    "        auc_cov.append(round(auc_ind_cov, 3))\n",
    "        ci_auc.append(ci_auc_ind)\n",
    "        auc.append(round(auc_ind, 3))\n",
    "        err.append(round(err_ind, 3))\n",
    "        fpr_all.append(fpr)\n",
    "        tpr_all.append(tpr)\n",
    "        p_fpr_all.append(p_fpr)\n",
    "        p_tpr_all.append(p_tpr)\n",
    "\n",
    "        conf_mat_ind = confusion_matrix(target_test, predicted)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_ind,\n",
    "                                      display_labels=mod.classes_)\n",
    "        disp.plot(cmap='Blues')\n",
    "        disp.ax_.set_title(headers[count])\n",
    "        count += 1\n",
    "        print(\"\\n\")\n",
    "\n",
    "        plot_auc(fpr, tpr, auc_ind)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Print metrics resulted\n",
    "    data = [acc_train, acc_test, ci_acc, acc_balanced,\n",
    "            ci_bacc, auc_delong, ci_auc, auc_cov, err]\n",
    "    print(tabulate(data, headers))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return fpr_all, tpr_all, p_fpr_all, p_tpr_all\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"This functions performs the training process\"\"\"\n",
    "\n",
    "    print(\"Ensembles training process starts.........................\")\n",
    "    model_1.train()\n",
    "    model_2.train()\n",
    "    model_3.train()\n",
    "    model_4.train()\n",
    "\n",
    "    for batch_idx, sample_batched in enumerate(train_loader):\n",
    "        if batch_idx > stop_train-1:\n",
    "          break\n",
    "        \n",
    "        # Input data and targets preparation\n",
    "        data = sample_batched['image'].float()\n",
    "        data_shape = data.shape\n",
    "        data_1 = torch.reshape(data[:,0,:,:],(data_shape[0],1,\n",
    "                                              data_shape[2], data_shape[3]))\n",
    "        data_2 = torch.reshape(data[:,1,:,:],(data_shape[0],1,\n",
    "                                              data_shape[2], data_shape[3]))\n",
    "        data_3 = torch.reshape(data[:,2,:,:],(data_shape[0],1,\n",
    "                                              data_shape[2], data_shape[3]))\n",
    "        data_4 = torch.reshape(data[:,3,:,:],(data_shape[0],1,\n",
    "                                              data_shape[2], data_shape[3]))\n",
    "        target = sample_batched['label_patient'].int()\n",
    "        target_1 = sample_batched['label_l_cc'].int()\n",
    "        target_2 = sample_batched['label_l_mlo'].int()\n",
    "        target_3 = sample_batched['label_r_cc'].int()\n",
    "        target_4 = sample_batched['label_r_mlo'].int()\n",
    "        #target = target.reshape([len(target)])\n",
    "        data_1, data_2, data_3, data_4 = Variable(data_1), Variable(data_2), Variable(data_3), Variable(data_4)\n",
    "        target = Variable(target)\n",
    "        target_1, target_2, target_3, target_4 = Variable(target_1), Variable(target_2), Variable(target_3), Variable(target_4)\n",
    "\n",
    "        # Independent training per channel\n",
    "        hiddenOut = model_1.forwardToHidden(data_1) # First channel\n",
    "        optimizer_1.train(inputs=hiddenOut, targets=target_1)\n",
    "\n",
    "        hiddenOut = model_2.forwardToHidden(data_2) # Second channel\n",
    "        optimizer_2.train(inputs=hiddenOut, targets=target_2)\n",
    "\n",
    "        hiddenOut = model_3.forwardToHidden(data_3) # Third channel\n",
    "        optimizer_3.train(inputs=hiddenOut, targets=target_3)\n",
    "\n",
    "        hiddenOut = model_3.forwardToHidden(data_4) # Third channel\n",
    "        optimizer_3.train(inputs=hiddenOut, targets=target_4)\n",
    "    \n",
    "    print(\"Ensembles training process ends...........................\")\n",
    "\n",
    "def train_accuracy():\n",
    "    \"\"\"This functions test the network using the training set.\n",
    "    \n",
    "       outputs:\n",
    "          output_1 = PDFs from first channel [# classes, # subjects]\n",
    "          output_2 = PDFs from second channel [# classes, # subjects]\n",
    "          output_3 = PDFs from third channel [# classes, # subjects]\n",
    "          target = labels of each subject\"\"\"\n",
    "\n",
    "    print(\"Ensembles training testing starts.........................\")\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "    model_3.eval()\n",
    "    model_4.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample_batched in enumerate(train_loader):\n",
    "            if batch_idx > stop_train-1:\n",
    "              break\n",
    "\n",
    "            # Input data and targets preparation\n",
    "            data = sample_batched['image'].float()\n",
    "            data_shape = data.shape\n",
    "            data_1 = torch.reshape(data[:,0,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_2 = torch.reshape(data[:,1,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_3 = torch.reshape(data[:,2,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_4 = torch.reshape(data[:,3,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            target = sample_batched['label_patient'].int()\n",
    "            target_1 = sample_batched['label_l_cc'].int()\n",
    "            target_2 = sample_batched['label_l_mlo'].int()\n",
    "            target_3 = sample_batched['label_r_cc'].int()\n",
    "            target_4 = sample_batched['label_r_mlo'].int()\n",
    "            #target = target.reshape([len(target)])\n",
    "            data_1, data_2, data_3, data_4 = Variable(data_1), Variable(data_2), Variable(data_3), Variable(data_4)\n",
    "            target = Variable(target)\n",
    "            target_1, target_2, target_3, target_4 = Variable(target_1), Variable(target_2), Variable(target_3), Variable(target_4)\n",
    "\n",
    "            output_1 = model_1.forward(data_1) # First channel\n",
    "            output_2 = model_2.forward(data_2) # Second channel\n",
    "            output_3 = model_3.forward(data_3) # Third channel\n",
    "            output_4 = model_4.forward(data_4) # Fourth channel\n",
    "\n",
    "    print(\"Ensembles training testing ends...........................\")\n",
    "    return output_1, output_2, output_3, output_4, target, target_1, target_2, target_3, target_4\n",
    "\n",
    "\n",
    "def test():\n",
    "    \"\"\"This functions test the network using the testing set.\n",
    "    \n",
    "       outputs:\n",
    "          output_1 = PDFs from first channel [# classes, # subjects]\n",
    "          output_2 = PDFs from second channel [# classes, # subjects]\n",
    "          output_3 = PDFs from third channel [# classes, # subjects]\n",
    "          target = labels of each subject\"\"\"\n",
    "\n",
    "    print(\"Ensembles testing starts..................................\")\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "    model_3.eval()\n",
    "    model_4.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample_batched in enumerate(test_loader):\n",
    "            if batch_idx > stop_test-1:\n",
    "              break\n",
    "\n",
    "            # Input data and targets preparation\n",
    "            data = sample_batched['image'].float()\n",
    "            data_shape = data.shape\n",
    "            data_1 = torch.reshape(data[:,0,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_2 = torch.reshape(data[:,1,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_3 = torch.reshape(data[:,2,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            data_4 = torch.reshape(data[:,3,:,:],(data_shape[0],1,\n",
    "                                                  data_shape[2], data_shape[3]))\n",
    "            target = sample_batched['label_patient'].int()\n",
    "            target_1 = sample_batched['label_l_cc'].int()\n",
    "            target_2 = sample_batched['label_l_mlo'].int()\n",
    "            target_3 = sample_batched['label_r_cc'].int()\n",
    "            target_4 = sample_batched['label_r_mlo'].int()\n",
    "            #target = target.reshape([len(target)])\n",
    "            data_1, data_2, data_3, data_4 = Variable(data_1), Variable(data_2), Variable(data_3), Variable(data_4)\n",
    "            target = Variable(target)\n",
    "            target_1, target_2, target_3, target_4 = Variable(target_1), Variable(target_2), Variable(target_3), Variable(target_4)\n",
    "\n",
    "            output_1 = model_1.forward(data_1) # First channel\n",
    "            output_2 = model_2.forward(data_2) # Second channel\n",
    "            output_3 = model_3.forward(data_3) # Third channel\n",
    "            output_4 = model_4.forward(data_4) # Fourth channel\n",
    "        \n",
    "    return output_1, output_2, output_3, output_4, target, target_1, target_2, target_3, target_4\n",
    "\n",
    "# Complete MCNN\n",
    "init=time.time()\n",
    "train()\n",
    "train_time = time.time()\n",
    "out_train_1, out_train_2, out_train_3, out_train_4, target_train, train_target_1, train_target_2, train_target_3, train_target_4 = train_accuracy()\n",
    "\n",
    "out_test_1, out_test_2, out_test_3, out_test_4, target_test, test_target_1, test_target_2, test_target_3, test_target_4 = test()\n",
    "test_time = time.time()\n",
    "FPR, TPR, P_FPR, P_TPR = final_classifier(out_train_1, out_train_2, out_train_3, out_train_4,\n",
    "                 out_test_1, out_test_2, out_test_3, out_test_4,\n",
    "                 target_train, target_test)\n",
    "ending=time.time()\n",
    "\n",
    "print(\"Training time: \", str(datetime.timedelta(seconds = train_time - init)), \"\\n\",\n",
    "      \"Testing time: \", str(datetime.timedelta(seconds = test_time - train_time)), \"\\n\",\n",
    "      \"Final process time: \", str(datetime.timedelta(seconds = ending - test_time)), \"\\n\",\n",
    "      \"Complete process time: \", str(datetime.timedelta(seconds = ending - init)))\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
